\hypertarget{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer}{\section{cheshire3.\-tokenizer.\-Regexp\-Find\-Tokenizer Class Reference}
\label{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer}\index{cheshire3.\-tokenizer.\-Regexp\-Find\-Tokenizer@{cheshire3.\-tokenizer.\-Regexp\-Find\-Tokenizer}}
}


Inheritance diagram for cheshire3.\-tokenizer.\-Regexp\-Find\-Tokenizer\-:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=244pt]{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for cheshire3.\-tokenizer.\-Regexp\-Find\-Tokenizer\-:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=326pt]{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hypertarget{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer_aa3e5a8e7471bae02f786e23117295625}{def {\bfseries \-\_\-\-\_\-init\-\_\-\-\_\-}}\label{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer_aa3e5a8e7471bae02f786e23117295625}

\item 
\hypertarget{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer_a72e943b46f8425def88ec49e320468cd}{def {\bfseries process\-\_\-string}}\label{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer_a72e943b46f8425def88ec49e320468cd}

\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hypertarget{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer_ad1b2418a2c4edc76414a5458b62ca7bb}{{\bfseries regexp}}\label{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer_ad1b2418a2c4edc76414a5458b62ca7bb}

\item 
\hypertarget{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer_a2d0c015caac7582d4b7aa690d2d6564b}{{\bfseries gaps}}\label{classcheshire3_1_1tokenizer_1_1_regexp_find_tokenizer_a2d0c015caac7582d4b7aa690d2d6564b}

\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
\begin{DoxyVerb}A tokenizer that returns all words that match the regex.\end{DoxyVerb}
 

The documentation for this class was generated from the following file\-:\begin{DoxyCompactItemize}
\item 
cheshire3/tokenizer.\-py\end{DoxyCompactItemize}
